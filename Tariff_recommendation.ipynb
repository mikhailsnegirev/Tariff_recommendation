{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. Нужно построить модель для задачи классификации, которая выберет подходящий тариф.\n",
    "\n",
    "Построим модель с максимально большим значением *accuracy*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Импортируем необходимые библиотеки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка данных не понадобится — мы её уже сделали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Известно:\n",
    "\n",
    "- сalls — количество звонков,\n",
    "\n",
    "- minutes — суммарная длительность звонков в минутах,\n",
    "\n",
    "- messages — количество sms-сообщений,\n",
    "\n",
    "- mb_used — израсходованный интернет-трафик в Мб,\n",
    "\n",
    "- is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Dataframe 3214 записей, это очень хороший показатель для исследования!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features содержит все признаки (характеристики), \n",
    "#которые будут использоваться для обучения модели, \n",
    "#а target — целевой признак, который модель будет пытаться предсказать.\n",
    "features = data.drop(['is_ultra'], axis=1)\n",
    "target = data['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спрятанной тестовой выборки нет. Значит, данные нужно разбить на три части: обучающую, валидационную и тестовую. Размеры тестового и валидационного наборов обычно равны. Исходные данные разбивают в соотношении 3:1:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Будем использовать функцию train_test_split(), чтобы разделить исходные данные (features и target) на обучающую выборку (features_train и target_train) и еще одну выборку, которую мы назовем \"промежуточной\" (features_test и target_test). Значение test_size=0.4 указывает, что 40% данных будут в этой \"промежуточной\" выборке, а 60% данных составят обучающую выборку.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.4, \n",
    "                                                                            random_state=12345\n",
    "                                                                           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Затем мы продолжим делить \"промежуточную\" выборку на валидационную и тестовую выборки:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(features_test, \n",
    "                                                                            target_test, \n",
    "                                                                            test_size=0.5, \n",
    "                                                                            random_state=12345\n",
    "                                                                           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поскольку мы использовали test_size=0.5, \"промежуточная\" выборка была поровну разделена на валидационную (features_valid и target_valid) и тестовую (features_test и target_test) выборки. Это означает, что размер валидационной и тестовой выборки равен 20% от размера исходных данных (0.4 * 0.5 = 0.2).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем проверить размеры этих выборок, чтобы убедиться в правильности разбиения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка:\n",
      "(1928, 4)\n",
      "(1928,)\n",
      "\n",
      "Валидационная выборка:\n",
      "(643, 4)\n",
      "(643,)\n",
      "\n",
      "Тестовая выборка:\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучающая выборка:\")\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "print(\"\\nВалидационная выборка:\")\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "\n",
    "print(\"\\nТестовая выборка:\")\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В результате разбиения мы получили:**\n",
    "\n",
    "1. Обучающую выборку размером 60% от исходных данных.\n",
    "2. Валидационную выборку размером 20% от исходных данных.\n",
    "3. Тестовую выборку размером 20% от исходных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DecisionTreeClassifier` - это структура данных для классификации деревом решений.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.7853810264385692 с гиперпараметром max_depth: = 3\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train) # обучим модель\n",
    "    predictions = model.predict(features_valid) # получим предсказания модели\n",
    "    result = accuracy_score(predictions, target_valid) # посчитаем качество модели\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_decisiontreeclassifier_depth = depth\n",
    "        \n",
    "print(\"Accuracy лучшей модели:\", best_result, \"с гиперпараметром max_depth: =\",best_decisiontreeclassifier_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RandomForestClassifier`**\n",
    "\n",
    "**Ещё один из алгоритмов классификации - случайный лес (random forest). Алгоритм обучает большое количество независимых друг от друга деревьев, а потом принимает решение на основе голосования. Случайный лес помогает улучшить результат предсказания и избежать переобучения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy наилучшей модели на валидационной выборке: 0.80248833592535 с гиперпараметром max_depth: = 8 и с n_estimators:= 8\n"
     ]
    }
   ],
   "source": [
    "best_model_randomforestclassifier = None\n",
    "best_result_randomforestclassifier = 0\n",
    "for est in range(1, 11):\n",
    "    for depth in range(1, 11):\n",
    "        model_randomforestclassifier = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth) # обучим модель с заданным количеством деревьев\n",
    "        model_randomforestclassifier.fit(features_train, target_train) # обучим модель на тренировочной выборке\n",
    "        result_randomforestclassifier = model_randomforestclassifier.score(features_valid, target_valid) # посчитаем качество модели на валидационной выборке\n",
    "        if result_randomforestclassifier > best_result_randomforestclassifier:\n",
    "            best_model_randomforestclassifier = model_randomforestclassifier # сохраним наилучшую модель\n",
    "            best_result_randomforestclassifier = model_randomforestclassifier.score(features_valid, target_valid)#  сохраним наилучшее значение метрики accuracy на валидационных данных\n",
    "            best_depth = depth \n",
    "            best_n_estimators = est\n",
    "\n",
    "print(\"Accuracy наилучшей модели на валидационной выборке:\", best_result_randomforestclassifier,  \"с гиперпараметром max_depth: =\",best_depth, \"и с n_estimators:=\", \n",
    "     best_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`LogisticRegression`**\n",
    "\n",
    "**Ещё один алгоритм машинного обучения - логистическая регрессия.\n",
    "В логистической регрессии параметров мало. Что-либо вызубрить по признакам в формуле не выйдет, поэтому и вероятность переобучения невелика.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели: 0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "model_logisticregression = LogisticRegression(random_state=12345)\n",
    "model_logisticregression.fit(features_train, target_train) # обучим модель\n",
    "predictions_logisticregression = model_logisticregression.predict(features_valid) # получим предсказания модели\n",
    "result_logisticregression = accuracy_score(predictions_logisticregression, target_valid) # посчитаем качество модели\n",
    "        \n",
    "print(\"Accuracy модели:\", result_logisticregression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "- Accuracy лучшей модели `DecisionTreeClassifier`: 0.7853810264385692 с гиперпараметром max_depth: = 3\n",
    "\n",
    "- Accuracy наилучшей модели `RandomForestClassifier`  на валидационной выборке: 0.80248833592535 с гиперпараметром max_depth: = 8 и с n_estimators:= 8\n",
    "\n",
    "- Accuracy модели  `LogisticRegression` : 0.7107309486780715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучашую Accuracy на валидационной выборке показала модель `RandomForestClassifier` : 0.80248833592535 с гиперпараметрами max_depth: = 8 и с n_estimators:= 8. \n",
    "\n",
    "Проверим эту же модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели на тестовой выборке: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "model_randomforestclassifier = RandomForestClassifier(random_state=12345, n_estimators=8, max_depth=8) # обучим модель с заданным количеством деревьев\n",
    "model_randomforestclassifier.fit(features_train, target_train) # обучим модель на обучающей выборке\n",
    "predictions_randomforestclassifier = model_randomforestclassifier.predict(features_test)\n",
    "result_randomforestclassifier = model_randomforestclassifier.score(features_test, target_test) # посчитаем качество модели на тестовой выборке\n",
    "\n",
    "print(\"Accuracy модели на тестовой выборке:\", result_randomforestclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy на тестовой выборке  модель `RandomForestClassifier` показала: 0.7962674961119751 с гиперпараметрами max_depth: = 8 и с n_estimators:= 8. \n",
    "\n",
    "Это может быть связано с тем, что модель переобучена на обучающей выборке, то есть модель хорошо работает на данных, на которых она обучалась, но не так хорошо работает на новых данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для проверки адекватности модели машинного обучения в Python, удобно использовать DummyClassifier из библиотеки scikit-learn. Это простой классификатор, который можно использовать в качестве эталонной модели.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DummyClassifier: 0.7060653188180405\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "clf.fit(features_train, target_train)\n",
    "result_clf = clf.score(features_valid, target_valid)\n",
    "print('Accuracy DummyClassifier:', result_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели RandomForestClassifier на валидационной выборке: 0.80248833592535\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy модели RandomForestClassifier на валидационной выборке:\", best_result_randomforestclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сказать, что модель RandomForestClassifier адекватна и эффективна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоговый вывод:**\n",
    "- Изучили наши данные, предобработка данных не требовалась — уже была сделана.\n",
    "\n",
    "\n",
    "- В результате разбиения данных на выборки мы получили: \n",
    "    - Обучающую выборку размером 60% от исходных данных.\n",
    "    - Валидационную выборку размером 20% от исходных данных.\n",
    "    - Тестовую выборку размером 20% от исходных данных.\n",
    "    \n",
    "    \n",
    "    \n",
    "- Исследовали модели и получили такие результаты: \n",
    "  -  Accuracy лучшей модели DecisionTreeClassifier: 0.7853810264385692 с гиперпараметром max_depth: = 3\n",
    "  - Accuracy наилучшей модели RandomForestClassifier на валидационной выборке: 0.80248833592535 с гиперпараметром max_depth: = 8 и с n_estimators:= 8\n",
    "  - Accuracy модели LogisticRegression : 0.7107309486780715\n",
    "    \n",
    "    \n",
    "- Проверили модель на тестовой выборке:\n",
    "  - Accuracy на тестовой выборке модель RandomForestClassifier показала: 0.7962674961119751 с гиперпараметрами max_depth: = 8 и с n_estimators:= 8. Это может быть связано с тем, что модель переобучена на обучающей выборке, то есть модель хорошо работает на данных, на которых она обучалась, но не так хорошо работает на новых данных.\n",
    "\n",
    "\n",
    "\n",
    "- Проверили модель на адекватность: \n",
    "     - Для проверки адекватности модели машинного обучения в Python использовали DummyClassifier из библиотеки scikit-learn. \n",
    "        - Можно сказать, что модель RandomForestClassifier адекватна и эффективна.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 391,
    "start_time": "2023-09-21T17:21:58.303Z"
   },
   {
    "duration": 121,
    "start_time": "2023-09-21T17:22:21.777Z"
   },
   {
    "duration": 18,
    "start_time": "2023-09-21T17:22:36.474Z"
   },
   {
    "duration": 12,
    "start_time": "2023-09-21T17:22:50.423Z"
   },
   {
    "duration": 912,
    "start_time": "2023-09-21T17:39:28.438Z"
   },
   {
    "duration": 6,
    "start_time": "2023-09-21T18:20:51.781Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-21T18:23:06.901Z"
   },
   {
    "duration": 5,
    "start_time": "2023-09-21T18:24:37.204Z"
   },
   {
    "duration": 5,
    "start_time": "2023-09-21T18:26:51.316Z"
   },
   {
    "duration": 1080,
    "start_time": "2023-09-23T15:32:40.300Z"
   },
   {
    "duration": 122,
    "start_time": "2023-09-23T15:32:41.382Z"
   },
   {
    "duration": 18,
    "start_time": "2023-09-23T15:32:41.506Z"
   },
   {
    "duration": 19,
    "start_time": "2023-09-23T15:32:41.526Z"
   },
   {
    "duration": 8,
    "start_time": "2023-09-23T15:32:41.548Z"
   },
   {
    "duration": 21,
    "start_time": "2023-09-23T15:32:41.558Z"
   },
   {
    "duration": 6,
    "start_time": "2023-09-23T15:32:41.581Z"
   },
   {
    "duration": 15,
    "start_time": "2023-09-23T15:32:41.589Z"
   },
   {
    "duration": 121,
    "start_time": "2023-09-23T15:42:02.941Z"
   },
   {
    "duration": 55,
    "start_time": "2023-09-23T15:42:16.705Z"
   },
   {
    "duration": 41,
    "start_time": "2023-09-23T15:42:20.697Z"
   },
   {
    "duration": 46,
    "start_time": "2023-09-23T15:43:20.019Z"
   },
   {
    "duration": 116,
    "start_time": "2023-09-23T15:43:50.929Z"
   },
   {
    "duration": 120,
    "start_time": "2023-09-23T15:44:15.460Z"
   },
   {
    "duration": 225,
    "start_time": "2023-09-23T15:44:19.464Z"
   },
   {
    "duration": 36,
    "start_time": "2023-09-23T15:44:24.931Z"
   },
   {
    "duration": 33,
    "start_time": "2023-09-23T15:44:54.117Z"
   },
   {
    "duration": 12,
    "start_time": "2023-09-23T15:53:45.284Z"
   },
   {
    "duration": 72,
    "start_time": "2023-09-23T15:54:41.272Z"
   },
   {
    "duration": 308,
    "start_time": "2023-09-23T15:54:49.002Z"
   },
   {
    "duration": 296,
    "start_time": "2023-09-23T15:56:53.104Z"
   },
   {
    "duration": 72,
    "start_time": "2023-09-23T15:56:56.284Z"
   },
   {
    "duration": 299,
    "start_time": "2023-09-23T15:56:58.317Z"
   },
   {
    "duration": 1182,
    "start_time": "2023-09-23T15:57:22.922Z"
   },
   {
    "duration": 31,
    "start_time": "2023-09-23T15:57:24.107Z"
   },
   {
    "duration": 18,
    "start_time": "2023-09-23T15:57:24.140Z"
   },
   {
    "duration": 36,
    "start_time": "2023-09-23T15:57:24.161Z"
   },
   {
    "duration": 38,
    "start_time": "2023-09-23T15:57:24.199Z"
   },
   {
    "duration": 46,
    "start_time": "2023-09-23T15:57:24.239Z"
   },
   {
    "duration": 48,
    "start_time": "2023-09-23T15:57:24.287Z"
   },
   {
    "duration": 48,
    "start_time": "2023-09-23T15:57:24.337Z"
   },
   {
    "duration": 120,
    "start_time": "2023-09-23T15:57:24.387Z"
   },
   {
    "duration": 310,
    "start_time": "2023-09-23T15:57:24.511Z"
   },
   {
    "duration": 1848,
    "start_time": "2023-09-23T15:58:37.782Z"
   },
   {
    "duration": 1860,
    "start_time": "2023-09-23T15:59:32.682Z"
   },
   {
    "duration": 1920,
    "start_time": "2023-09-23T16:00:09.201Z"
   },
   {
    "duration": 1983,
    "start_time": "2023-09-23T16:02:13.750Z"
   },
   {
    "duration": 75,
    "start_time": "2023-09-23T16:03:08.840Z"
   },
   {
    "duration": 4,
    "start_time": "2023-09-23T16:05:59.332Z"
   },
   {
    "duration": 27,
    "start_time": "2023-09-23T16:11:27.342Z"
   },
   {
    "duration": 27,
    "start_time": "2023-09-23T16:13:02.427Z"
   },
   {
    "duration": 27,
    "start_time": "2023-09-23T16:15:20.402Z"
   },
   {
    "duration": 28,
    "start_time": "2023-09-23T16:16:17.040Z"
   },
   {
    "duration": 27,
    "start_time": "2023-09-23T16:16:22.418Z"
   },
   {
    "duration": 27,
    "start_time": "2023-09-23T16:16:37.217Z"
   },
   {
    "duration": 30,
    "start_time": "2023-09-23T16:16:46.896Z"
   },
   {
    "duration": 150,
    "start_time": "2023-09-23T16:37:00.552Z"
   },
   {
    "duration": 37,
    "start_time": "2023-09-23T16:37:42.734Z"
   },
   {
    "duration": 3,
    "start_time": "2023-09-23T16:51:03.905Z"
   },
   {
    "duration": 5,
    "start_time": "2023-09-23T16:53:44.861Z"
   },
   {
    "duration": 3,
    "start_time": "2023-09-23T16:54:34.952Z"
   },
   {
    "duration": 2661,
    "start_time": "2023-09-23T17:52:52.045Z"
   },
   {
    "duration": 191,
    "start_time": "2023-09-23T17:52:54.707Z"
   },
   {
    "duration": 15,
    "start_time": "2023-09-23T17:52:54.900Z"
   },
   {
    "duration": 13,
    "start_time": "2023-09-23T17:52:54.917Z"
   },
   {
    "duration": 8,
    "start_time": "2023-09-23T17:52:54.932Z"
   },
   {
    "duration": 18,
    "start_time": "2023-09-23T17:52:54.942Z"
   },
   {
    "duration": 11,
    "start_time": "2023-09-23T17:52:54.964Z"
   },
   {
    "duration": 16,
    "start_time": "2023-09-23T17:52:54.977Z"
   },
   {
    "duration": 68,
    "start_time": "2023-09-23T17:52:54.994Z"
   },
   {
    "duration": 1756,
    "start_time": "2023-09-23T17:52:55.066Z"
   },
   {
    "duration": 33,
    "start_time": "2023-09-23T17:52:56.824Z"
   },
   {
    "duration": 38,
    "start_time": "2023-09-23T17:52:56.863Z"
   },
   {
    "duration": 4,
    "start_time": "2023-09-23T17:52:56.902Z"
   },
   {
    "duration": 4,
    "start_time": "2023-09-23T17:52:56.908Z"
   },
   {
    "duration": 105,
    "start_time": "2023-09-24T08:09:36.080Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
